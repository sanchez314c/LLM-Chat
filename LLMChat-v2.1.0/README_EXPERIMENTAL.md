# LLMChat v2.1.0-experimental - Advanced Dependencies Build

⚠️ **EXPERIMENTAL VERSION - NOT RECOMMENDED FOR PRODUCTION**

## Overview
Experimental build based on v2.0.0 modular architecture with additional heavy dependencies for advanced research and development.

## ⚠️ Warning
This version includes:
- LLVM/MLIR toolchain (~500MB)
- Triton GPU computing framework
- SilentCipher audio watermarking
- Other experimental dependencies

**Recommended Alternative:** Use `LLMChat-v2.0.0` for stable production deployment.

## Additional Features
- Advanced GPU computing via Triton
- Audio watermarking capabilities
- Extended ML/AI toolchain support
- Research-oriented experimental features

## Requirements
- Significant disk space (>2GB for dependencies)
- CUDA-capable GPU (recommended)
- High-end development machine
- Advanced technical knowledge

## Installation
```bash
# Only attempt if you have the required resources
pip install -r requirements.txt
# Warning: This will download large ML/GPU frameworks
```

## Use Cases
- Academic research
- Advanced AI development
- GPU computing experiments
- Audio processing research
- **NOT for basic chat applications**

## Support
This experimental version is provided as-is for research purposes.
For stable chat functionality, please use:
- **LLMChat-v2.0.0** (recommended)
- **LLMChat-v1.0.0** (feature-complete)
- **LLMChat-v0.1.0** (basic)